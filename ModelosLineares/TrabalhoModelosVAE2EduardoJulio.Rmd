---
title: "Modelo de regressão para avaliar os pesos de pinguins no arquipélago Palmer"
author: "Eduardo Freire Mangabeira, Julio Cesar dos Santos Magalhães"
date: "23/01/2022"
output: html_document
---



Os dados de palmerpenguins contêm medidas de tamanho para três espécies de pinguins observadas em três ilhas no Arquipélago Palmer, na Antártida.

Esses dados foram coletados de 2007 a 2009 pela Dra. Kristen Gorman com o [Palmer Station Long Term Ecological Research Program](https://pal.lternet.edu/), parte da [US Long Term Ecological Research Network](https://lternet.edu/).

Fonte: https://allisonhorst.github.io/palmerpenguins/


## Modelo de regressão


No presente trabalho, propomos um modelo de regressão para avaliar a influência das variáveis sexo, ano, ilha, espécie, comprimento do bico, profundidade do bico e comprimento da nadadeira na massa corporal em gramas de um pinguim do Arquipélago Palmer, que pode ser da espécie Adelie(pinguim-de-Adélia), Gentoo ou Chinstrap(Pinguim-de-barbicha). Descobrimos que o modelo que inclui as variáveis [blablabla] teve uma performance superior comparado aos outros e que existe[ou não existe] uma relação linear entre [blablabla] e a massa corporal dos pinguins.


### Váriaveis explicativas

- sex: Sexo do Pinguim. (variável binária)
- year: Ano de coleta do dado. (variável qualitativa)
- island: Ilha de origem do pinguim. (variável qualitativa)
- species: Espécie do pinguim.(variável qualitativa)
- bill_depth_mm: Profundidade do bico do pinguim em milímetros.(variável quantitativa contínua)
- flipper_length_mm: Comprimento da nadadeira do Pinguim em milímetros. (variável quantitativa contínua)
- body_mass_g: Massa corporal em gramas do pinguim.

### Variável resposta


- bill_length_mm: Comprimento do bico do pinguim em milímetros. (variável quantitativa - contínua)

# Dataset

```{r, warning=FALSE}
# install.packages("palmerpenguins")
library(palmerpenguins)
dataset <- palmerpenguins::penguins
```

## Limpeza do dataset


### Valores faltantes

Existem 11 linhas com valores faltantes no dataset. Para não prejudicar o experimento, retiramos todas as linhas em que pelo menos uma coluna não tenha um dado.

```{r warning=FALSE, message=FALSE, echo=FALSE}
library(tidyr)
library(dplyr)
library(purrr)
dados <- dataset %>% 
    tidyr::drop_na(names(dataset)) %>%
    dplyr::filter(species=="Gentoo") %>% 
    dplyr::select(bill_length_mm, everything(), -year)

```

### Conferindo outliers

Observando os box-plots é possível ver que não há valores discrepantes para quase todas as variáveis numéricas, com exceção da variável resposta.

```{r}
boxplot(dados$"body_mass_g", ylab="body_mass_g")
boxplot(dados$"bill_depth_mm", ylab="bill_depth_mm")
boxplot(dados$"flipper_length_mm", ylab="flipper_length_mm")
boxplot(dados$"bill_length_mm", ylab="bill_length_mm")
```

Testamos um novo modelo retirando o valor discrepante usando o teste de Grubbs para identificá-lo.

```{r}
library(outliers)
outlier <- outliers::grubbs.test(dados$bill_length_mm)
if(outlier$p.value < 0.05){
  dados <- dados %>%
    dplyr::filter(bill_length_mm != max(bill_length_mm))
}

boxplot(dados$bill_length_mm, ylab="bill_length_mm")
```


### Transformando a variável sexo em numérica

Para poder realizar operações com a variável `sexo`, escolhemos "feminino" como categoria de referência e transformamos a coluna em numérica.

```{r}
dados$sex <- ifelse(dados$sex=="female", 1, 0)
```

### One-hot encoding das variáveis categóricas

Criamos 3 variáveis indicadoras para a variável categórica `ilha`.

```{r, message=FALSE, warning=FALSE}
library(mltools)
library(data.table)
dados <- mltools::one_hot(data.table::as.data.table(dados))
dados
```


# Seleção do modelo

Usaremos o método de "todos os modelos possíveis" para escolher o melhor modelo. 


```{r}

ajusta_todos_modelos <- function(dados){
    explicativas <- colnames(dados)[2:ncol(dados)]
    ajustes <- list()
    for (i in seq_along(explicativas)) {
      combinacoes <- combn(explicativas, i)
      soma_explicativas <- apply(combinacoes, 2, paste, collapse="+")
      ajustes[[i]] <- paste0("bill_length_mm~", soma_explicativas)
    }
    ajustes <- sapply(unlist(ajustes), as.formula)
    modelos <- lapply(ajustes, lm, data=dados)
    return(modelos)
}

```

## Métricas de avaliação

Avaliaremos as métricas $R^2$, $R^2$ ajustado, estatística PRESS e informação de Akaike(AIC).

Escolhemos os seguintes critérios para tornar automática a comparação entre modelos:

- Diferença entre o $R^2$ do modelo mais simples e do mais completo menor que 0.05,

- $R^2$ do modelo mais recente for maior que o modelo antigo em 0.09.

- AIC do modelo antigo maior que do modelo novo.

- Estatística PRESS do modelo antigo maior que do modelo novo.

Se TODOS os critérios acima são respeitados, o modelo novo é escolhido.


```{r message=FALSE, warning=FALSE}

complexidade <- function(modelo){
    return(length(coefficients(modelo)))
}

calcula_press <- function(modelo){
    influencia <- residuals(modelo)/ (1-lm.influence(modelo)$hat)
    return(sum(influencia^2))
}


confere_diferenca_metricas <- function(modelo_novo, modelo_antigo){
    # R2 e R2 Ajustado
    s_modelo_novo = summary(modelo_novo)
    s_modelo_antigo = summary(modelo_antigo)
    diff_r2 <- s_modelo_novo$r.squared - s_modelo_antigo$r.squared
    diff_r2_ajustado<- s_modelo_novo$adj.r.squared - s_modelo_antigo$adj.r.squared
    r2_significativo <- abs(diff_r2) <= 0.03
    r2_ajustado_significativo <- abs(diff_r2_ajustado) <= 0.03
    r2_grande <- diff_r2 > 0 & abs(diff_r2) >= 0.07
    r2_ajustado_grande <- diff_r2_ajustado > 0 & abs(diff_r2) >= 0.07
    
    
    # PRESS e AIC
    aic <- AIC(modelo_novo) < AIC(modelo_antigo)
    press <- calcula_press(modelo_novo) < calcula_press(modelo_antigo)
    
    diff_significativa <- r2_significativo & r2_ajustado_significativo & aic & press
    if(diff_significativa){
        return("significativa")
    }
  
    # & aic & press
    diff_grande <- r2_grande & r2_ajustado_grande & aic & press
    if(diff_grande){
        return("grande")
    }
    
    return("não significante")
}

escolhe_melhor_modelo <- function(modelos){
    melhor_modelo = modelos[[1]]
    for(modelo in modelos){
        diferenca_metricas <- confere_diferenca_metricas(modelo, melhor_modelo)
        if((complexidade(melhor_modelo) > complexidade(modelo)) & diferenca_metricas == "significativa"){
            melhor_modelo <- modelo
        }
        
        if(diferenca_metricas == "grande"){
            melhor_modelo <- modelo 
        }
    }
    return(melhor_modelo)
    }
```


## Todos os modelos possíveis


```{r message=FALSE, warning=FALSE}

seleciona_modelo <- function(dados){
    melhor_modelo <- dados %>%
        ajusta_todos_modelos() %>% 
        escolhe_melhor_modelo()
    return(melhor_modelo)
}

model <- seleciona_modelo(dados)
summary(model)

```

## Modelo escolhido

Como os modelos dos artigos de referência são modelos lineares generalizados, nossa técnica de encontrar o melhor modelo linear foi falha. Usamos o método de todos os modelos possíveis, mas chegamos à conclusão de que o modelo não reforçava o que diz a literatura e não respeitava as suposições de um modelo linar. Portanto, testamos outros modelos que usam variáveis que aparecem normalmente nas principais publicações sobre os dados apresentados.

Descobrimos que o modelo que inclui as variaveis massa corporal em grama, sexo e comprimento da nadadeira, e o que melhor se ajusta aos dados com um $R2$ = 0,4919, que é razoavelmente bom para sugerir uma boa qualidade do ajuste do modelo que tem como variável resposta o logaritmo natural do comprimento do bico do penguim.

$$log(Y) = \beta_0  + \beta_1X_1  + \beta_2X_2 + \beta_3X_3 + \epsilon$$
Onde Y corresponde ao comprimento do bico em milímetros, $X_1$ massa corporal em
gramas, $_2$ sexo, $X_3$ tamanho da nadadeira em milímetros e $\epsilon$ os resíduos.



## Modelo escolhido

```{r}
model <- lm(log(dados$bill_length_mm)~dados$body_mass_g + dados$sex + dados$flipper_length_mm)
summary(model)
```

Considerando as hipóteses das variáveis explicativas serem ou não significativas, de acordo com os p-valores, ao nível de significância de 5%, temos evidências para rejeitar que as variáveis explicativas e o intercepto são não significativos.

Pela a hipótese da significância do modelo, o p-valor calculado a partir da estatística F mostra que ao nível de significância de 5%, temos evidências para rejeitar que o modelo é não significativo.

O $R^2$ mostra que conseguimos explicar por volta de 47% dos erros do modelo, o que para este presente trabalho é satisfatório para contribuir na sustentação de nossa hipótese inicial de que há uma relação linear entre as variáveis explicativas e a variável resposta.

# Interpretação dos coeficientes do modelo

- Intercepto: Caso não houvessem outras variáveis influenciando, o logaritmo do tamanho base do bico seria de 3.069 mm.

- Massa corporal em gramas: a cada grama, o logaritmo do comprimento do bico do Gentoo aumenta a uma taxa de 0,00003 mm.

- Sexo: Como fêmeas compoem a referência da variável, o coeficiente indica que o logaritmo do bico das fêmeas é menor em comprimento em -0,02871 mm.

- Comprimento da nadadeira: A cada milímetro da nadadeira o logaritmo do bico do pinguim Gentoo aumenta em 0,002992 mm.

## Análise dos resíduos

Com o modelo ajustado, prosseguimos para verificar as suposições do modelo com gráficos
e testes.

## Homecedasticidade

Observando o gráfico dos resíduos, é possível notar que os resíduos não aparentam seguir um padrão.

```{r}
plot(fitted.values(model),rstandard(model),xlab="Valores Ajustados",ylab="Resíduos normalizados")
```

## Normalidade

Observando o histograma, podemos ver que os resíduos aparentam seguir uma distribuição normal.


```{r}
hist(model$residuals)
```
```{r}
qqnorm(model$residuals, pch = 1, frame = FALSE)
qqline(model$residuals, col = "steelblue", lwd = 2)
```

## Linearidade

Usamos o teste de falta de ajuste para verificar a linearidade entre as variáveis resposta e explicativas. A conclusão foi que não há evidências ao nível de 5% de significância para rejeitar a hipótese nula de que o modelo mais simples é adequado aos dados.

```{r, message=FALSE}
full_model <- lm(log(dados$bill_length_mm) ~., data=dados)
anova(model, full_model)
```

## Independência

Temos informações sobre a sequência de coleta dos dados, portanto usaremos o teste de Durbin-Watson para verificar independência entre os erros, onde a hipótese nula é de que os erros não são autocorrelacionados entre si. Como o p-valor da estatística de teste é maior que 0.05, ao nível de significância de 5% não há evidências para rejeitar a hipótese nula, e assim, o modelo respeita mais uma suposição.

```{r, message=FALSE, warning=FALSE}
library(car)
car::durbinWatsonTest(model)
```

# Detectando valores influentes

Observando a tabela com os DFBETAS é possível perceber que não há nenhum valor que ultrapasse o limiar $\frac{2}{\sqrt{118}}$, logo não há de se preocupar com valores influentes alterando o ajuste do modelo.

```{r, message=FALSE, warning=FALSE}
limiar <- 2/sqrt(118)
dfbetas <- dfbeta(model)
dfbetas <- as.data.frame(dfbetas)
names(dfbetas) <- c("intercept", "body_mass_g", "sex", "flipper_length_mm")
head(dfbetas)
```

Como os fatores de aumento de variância não são muito altos é seguro afirmar que não temos problemas graves de multicolinearidade seguindo essse modelo.

```{r}
library(DAAG)
DAAG::vif(model)

```

